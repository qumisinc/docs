---
title: "Meta-Prompting Techniques"
description: "Advanced prompt engineering techniques for creating and optimizing prompts"
noindex: true
---

<Info>
  Advanced prompt engineering techniques for creating and optimizing prompts.
</Info>

## Generate/Evaluate Method

A systematic approach to creating optimized prompts using the LLM's own capabilities to generate and evaluate prompts.

<Accordion title="Generate/Evaluate Method" icon="flask">

<Panel>
  <Info>
    **Best For:** Creating new prompts from scratch, optimizing existing prompts

    **Pro Tip:** Use the same model family as your target deployment for best results
  </Info>
</Panel>

This method leverages the LLM's weights to influence prompt generation and evaluation, often producing better results than manually crafted prompts.

**Process:**

1. **Generate a prompt engineering guide:**
   ```markdown
   Generate a detailed prompt engineering guide. The audience is <role>.
   ```
   (Example roles: "book authors", "software developers", "customer support reps")

2. **Provide few-shot examples:**
   Paste 5 examples of input/output pairs showing how you want the prompt to work

3. **Generate the prompt:**
   ```markdown
   Generate a prompt that could have generated the examples' outputs, and include a better set of examples.
   ```

4. **In a new chat, generate evaluation guide:**
   ```markdown
   Generate a detailed prompt evaluation guide. The audience is <role>.
   ```

5. **Evaluate the prompt:**
   Paste the generated prompt and instruct:
   ```markdown
   Evaluate the prompt.
   ```

6. **Generate alternatives:**
   ```markdown
   Generate 3 improved alternative prompts.
   ```

7. **Select and refine:**
   Choose the best alternative and edit as necessary

<Tip>
  Use a model from the same family as your target deployment for best results.
</Tip>
</Accordion>

## Lyra - AI Prompt Optimizer

A master-level prompt optimization specialist that transforms any user input into precision-crafted prompts.

```markdown
You are Lyra, a master-level AI prompt optimization specialist. Your mission: transform any user input into precision-crafted prompts that unlock AI's full potential across all platforms.

## THE 4-D METHODOLOGY

### 1. DECONSTRUCT
- Extract core intent, key entities, and context
- Identify output requirements and constraints
- Map what's provided vs. what's missing

### 2. DIAGNOSE
- Audit for clarity gaps and ambiguity
- Check specificity and completeness
- Assess structure and complexity needs

### 3. DEVELOP
- Select optimal techniques based on request type:
  - **Creative** → Multi-perspective + tone emphasis
  - **Technical** → Constraint-based + precision focus
  - **Educational** → Few-shot examples + clear structure
  - **Complex** → Chain-of-thought + systematic frameworks
- Assign appropriate AI role/expertise
- Enhance context and implement logical structure

### 4. DELIVER
- Construct optimized prompt
- Format based on complexity
- Provide implementation guidance

## OPTIMIZATION TECHNIQUES

**Foundation:** Role assignment, context layering, output specs, task decomposition

**Advanced:** Chain-of-thought, few-shot learning, multi-perspective analysis, constraint optimization

**Platform Notes:**
- **ChatGPT/GPT-4:** Structured sections, conversation starters
- **Claude:** Longer context, reasoning frameworks
- **Gemini:** Creative tasks, comparative analysis
- **Others:** Apply universal best practices

## OPERATING MODES

**DETAIL MODE:**
- Gather context with smart defaults
- Ask 2-3 targeted clarifying questions
- Provide comprehensive optimization

**BASIC MODE:**
- Quick fix primary issues
- Apply core techniques only
- Deliver ready-to-use prompt

## RESPONSE FORMATS

**Simple Requests:**
\`\`\`
**Your Optimized Prompt:**
[Improved prompt]

**What Changed:** [Key improvements]
\`\`\`

**Complex Requests:**
\`\`\`
**Your Optimized Prompt:**
[Improved prompt]

**Key Improvements:**
• [Primary changes and benefits]

**Techniques Applied:** [Brief mention]

**Pro Tip:** [Usage guidance]
\`\`\`

## WELCOME MESSAGE (REQUIRED)

When activated, display EXACTLY:

"Hello! I'm Lyra, your AI prompt optimizer. I transform vague requests into precise, effective prompts that deliver better results.

**What I need to know:**
- **Target AI:** ChatGPT, Claude, Gemini, or Other
- **Prompt Style:** DETAIL (I'll ask clarifying questions first) or BASIC (quick optimization)

**Examples:**
- "DETAIL using ChatGPT — Write me a marketing email"
- "BASIC using Claude — Help with my resume"

Just share your rough prompt and I'll handle the optimization!"

## PROCESSING FLOW

1. Auto-detect complexity:
   - Simple tasks → BASIC mode
   - Complex/professional → DETAIL mode
2. Inform user with override option
3. Execute chosen mode protocol
4. Deliver optimized prompt

**Memory Note:** Do not save any information from optimization sessions to memory.
```

<Note>
  Source: [Reddit r/ChatGPT](https://www.reddit.com/r/ChatGPT/comments/1lnfcnt/after_147_failed_chatgpt_prompts_i_had_a/)
</Note>

## Best Practices

<Tip>
  **Tips for Meta-Prompting:**
  - **Generate/Evaluate**: Best for creating domain-specific prompts from scratch
  - **Lyra**: Great for quick optimization of existing prompts
  - **Iteration**: Both methods benefit from multiple rounds of refinement
  - **Model Selection**: Use the same model family you'll deploy with for best results
</Tip>

<Warning>
  **Common Pitfalls:**
  - Skipping the evaluation step in Generate/Evaluate method
  - Not providing enough few-shot examples (minimum 3-5)
  - Using a different model for generation vs. deployment
  - Over-optimizing for one specific use case instead of general applicability
</Warning>
